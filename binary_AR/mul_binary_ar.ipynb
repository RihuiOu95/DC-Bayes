{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74345dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# Calling libraries:\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np, time, matplotlib.pyplot as plt, numpy.random as npr, pystan as ps, pickle\n",
    "from pylab import plot, show, legend\n",
    "from time import time\n",
    "from scipy.stats import *\n",
    "from tqdm import trange\n",
    "from functions import *\n",
    "#import statsmodels.api as sm\n",
    "import multiprocessing\n",
    "import arviz as az\n",
    "import random\n",
    "import os\n",
    "import pathlib\n",
    "#multiprocessing.set_start_method(\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac7bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def generate_Y(X, T, alph, b, c):\n",
    "    y = np.zeros(T).astype(int)\n",
    "    prob = np.zeros(T)\n",
    "\n",
    "    for t in range(p) :\n",
    "        prob[t] = 1/(1+np.exp(-(c+X[t].dot(b)))) \n",
    "        y[t] = npr.binomial(n=1,p=prob[t],size=1)\n",
    "    for t in np.arange(p+1,T) :\n",
    "        prob[t] = 1/(1+np.exp(-(c+alph.dot(y[(t-p):t])+X[t].dot(b)))) \n",
    "        y[t] = npr.binomial(n=1,p=prob[t],size=1)\n",
    "    return prob, y\n",
    "\n",
    "def cal_ess(prob):\n",
    "    samp_dict = {'prob' : prob}\n",
    "    data = az.from_dict(posterior=samp_dict)\n",
    "    ess = az.ess(data)\n",
    "    return ess['prob'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35b3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(190)\n",
    "sym_param = lambda entry, p : np.array([entry] * (p // 2) + [0] + [-entry] * (p // 2)) if p % 2 != 0 else np.array([entry] * (p // 2) + [-entry] * (p // 2))\n",
    "same_param = lambda entry, p: np.array([entry] * p)\n",
    "p = 5\n",
    "T = 10_000\n",
    "alph = same_param(0.2, p)\n",
    "prob = np.zeros(T)\n",
    "c = -0.1\n",
    "q = 5\n",
    "b = sym_param(0.5, q)\n",
    "alph_entries = [0.05, 0.25, 0.5]\n",
    "n_exp = len(alph_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2789ce7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.05, 0.05, 0.05, 0.05, 0.05],\n",
       "        [0.25, 0.25, 0.25, 0.25, 0.25],\n",
       "        [0.5 , 0.5 , 0.5 , 0.5 , 0.5 ]]),\n",
       " array([ 0.5,  0.5,  0. , -0.5, -0.5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphs = np.array([same_param(alph,p) for alph in alph_entries])\n",
    "alphs,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bb1864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot X, use the same X\n",
    "X = generate_X(T, q)\n",
    "f = plt.figure(figsize=(18,2))\n",
    "for i in range(q) :\n",
    "    plt.subplot(1,q,i+1)\n",
    "    plt.plot(X[:,i])\n",
    "    plt.xlim(-0.005*T,1.005*T)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f750b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alph is 0.05, ESS ratio is 0.8155490607556611\n",
      "alph is 0.25, ESS ratio is 0.43650172832188383\n",
      "alph is 0.5, ESS ratio is 0.2966432757955168\n"
     ]
    }
   ],
   "source": [
    "prob, y = generate_Y(X, T, alph, b, c)\n",
    "datas = {}\n",
    "for i in range(n_exp):\n",
    "    alph = same_param(alph_entries[i],p)\n",
    "    alph_str = str(alph[0])\n",
    "    prob, y = generate_Y(X, T, alph, b, c)\n",
    "    datas[alph_str] = {}\n",
    "    # save datas\n",
    "    datas[alph_str]['prob'] = prob\n",
    "    datas[alph_str]['y'] = y\n",
    "    datas[alph_str]['alpha'] = alph\n",
    "    datas[alph_str]['b'] = b\n",
    "    datas[alph_str]['c'] = c\n",
    "    datas[alph_str]['X'] = X\n",
    "    print(\"alph is \" +alph_str+f\", ESS ratio is {cal_ess(prob) / T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c410b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('multi_sims')\n",
    "file = open(\"multiple_sims/datas.pkl\", \"wb\")\n",
    "pickle.dump(datas, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c14989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_9b9d3a3601f9a90c225c8eef68304f39 NOW.\n",
      "In file included from /var/folders/vm/bnpn0t152gn54b0_nhp78xf40000gp/T/pystan_xikqmtuo/stanfit4anon_model_9b9d3a3601f9a90c225c8eef68304f39_447663330172494378.cpp:771:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:4:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1944:\n",
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: \"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      " ^\n",
      "/var/folders/vm/bnpn0t152gn54b0_nhp78xf40000gp/T/pystan_xikqmtuo/stanfit4anon_model_9b9d3a3601f9a90c225c8eef68304f39_447663330172494378.cpp:9546:30: warning: comparison of integers of different signs: 'Py_ssize_t' (aka 'long') and 'std::__1::vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >::size_type' (aka 'unsigned long') [-Wsign-compare]\n",
      "    __pyx_t_12 = ((__pyx_t_9 != __pyx_v_fitptr->param_names_oi().size()) != 0);\n",
      "                   ~~~~~~~~~ ^  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /var/folders/vm/bnpn0t152gn54b0_nhp78xf40000gp/T/pystan_xikqmtuo/stanfit4anon_model_9b9d3a3601f9a90c225c8eef68304f39_447663330172494378.cpp:780:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/pystan/py_var_context.hpp:12:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/pystan/stan/src/stan/io/dump.hpp:6:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/pystan/stan/lib/stan_math/stan/math/prim/mat.hpp:336:\n",
      "In file included from /opt/anaconda3/lib/python3.9/site-packages/pystan/stan/lib/stan_math/stan/math/prim/mat/prob/poisson_log_glm_log.hpp:5:\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pystan/stan/lib/stan_math/stan/math/prim/mat/prob/poisson_log_glm_lpmf.hpp:64:59: warning: unused typedef 'T_alpha_val' [-Wunused-local-typedef]\n",
      "      typename partials_return_type<T_alpha>::type>::type T_alpha_val;\n",
      "                                                          ^\n",
      "In file included from /var/folders/vm/bnpn0t152gn54b0_nhp78xf40000gp/T/pystan_xikqmtuo/stanfit4anon_model_9b9d3a3601f9a90c225c8eef68304f39_447663330172494378.cpp:783:\n",
      "/var/folders/vm/bnpn0t152gn54b0_nhp78xf40000gp/T/pystan_xikqmtuo/anon_model_9b9d3a3601f9a90c225c8eef68304f39.hpp:158:24: warning: unused typedef 'local_scalar_t__' [-Wunused-local-typedef]\n",
      "        typedef double local_scalar_t__;\n",
      "                       ^\n",
      "4 warnings generated.\n"
     ]
    }
   ],
   "source": [
    "# run the simulation pipeline here\n",
    "sm = ps.StanModel(file=\"model_binaryAR.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375fbe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_mcmc(alph_entry, n_iter=500):\n",
    "    tstart, tend = 0, T\n",
    "    alph_str = str(alph_entry)\n",
    "    \n",
    "    # extract data\n",
    "    print(\"Doing Full MCMC for alpha=\"+alph_str)\n",
    "    X, y = datas[alph_str]['X'], datas[alph_str]['y']\n",
    "    data = dict(T=tend-tstart, p=p, q=q, y=y[tstart:tend], X=X[tstart:tend,:], power=1)\n",
    "    \n",
    "    start = time()\n",
    "    fit = sm.sampling(data=data, thin=1, n_jobs = 8, chains=n_chains, init=\"random\", iter=n_iter)\n",
    "    mle = sm.optimizing(data=data)\n",
    "    # make path\n",
    "    path = 'multiple_sims/'+alph_str\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    #\n",
    "    print(round((time()-start)/60,2), \"minutes to run\")\n",
    "    trace = fit.extract()\n",
    "    file = open(path+\"/full_mcmc.pkl\", \"wb\")\n",
    "    pickle.dump(trace, file)\n",
    "    file.close()\n",
    "    file = open(path+\"/full_mle.pkl\", \"wb\")\n",
    "    pickle.dump(mle, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "241eb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_iter = 20\n",
    "#m = 10\n",
    "def dc_mcmc(alph_entry,n_iter=500,m=10):\n",
    "    alph_str = str(alph_entry)\n",
    "    tstarts = np.arange(m).astype(int)\n",
    "    tends = 1 + tstarts\n",
    "    tstarts *= int(T/m)\n",
    "    tends *= int(T/m)\n",
    "    print(\"Doing DC MCMC for alpha=\"+alph_str)\n",
    "    for i in range(m) :\n",
    "        tstart, tend = tstarts[i], tends[i]\n",
    "        X, y = datas[alph_str]['X'], datas[alph_str]['y']\n",
    "        data = dict(T=tend-tstart, p=p, q=q, y=y[tstart:tend], X=X[tstart:tend,:], power=T/(tend-tstart))\n",
    "        \n",
    "        # run mcmc\n",
    "        fit = sm.sampling(data=data, thin=1, n_jobs=8, chains=n_chains, init=\"random\", iter=n_iter)\n",
    "        trace = fit.extract()\n",
    "        \n",
    "        # make path\n",
    "        path = 'multiple_sims/'+alph_str\n",
    "        pathlib.Path(path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # save files\n",
    "        file = open(path+\"/mcmc_wb_chunk\"+str(i+1)+\".pkl\", \"wb\")\n",
    "        pickle.dump(trace, file)\n",
    "        file.close()\n",
    "        mle = sm.optimizing(data=data)\n",
    "        file = open(path+\"/mle_chunk\"+str(i+1)+\".pkl\", \"wb\")\n",
    "        pickle.dump(mle, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4047a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Full MCMC for alpha=0.05\n",
      "\n",
      "Gradient evaluation took 0.010437 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 104.37 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "2.16 minutes to run\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 64.6604 seconds (Warm-up)\n",
      "               64.7993 seconds (Sampling)\n",
      "               129.46 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -18542.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -6045.67   0.000195823      0.121177      0.6852      0.6852       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Doing DC MCMC for alpha=0.05\n",
      "\n",
      "Gradient evaluation took 0.000864 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.64 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.15455 seconds (Warm-up)\n",
      "               6.33397 seconds (Sampling)\n",
      "               12.4885 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -16937.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5976.87   0.000113849      0.147317           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5976.87   0.000279842      0.083244           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000928 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.28 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.52575 seconds (Warm-up)\n",
      "               6.44217 seconds (Sampling)\n",
      "               12.9679 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -16454.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      17       -6056.1   0.000220412     0.0606158      0.9372      0.9372       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000912 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.12 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.72935 seconds (Warm-up)\n",
      "               6.42387 seconds (Sampling)\n",
      "               13.1532 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -14873.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -6057.08   0.000380647      0.124515      0.8344      0.8344       19   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000879 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.79 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.58356 seconds (Warm-up)\n",
      "               6.58345 seconds (Sampling)\n",
      "               13.167 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -16831.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      17      -5999.04   0.000221304      0.101239      0.7415      0.7415       18   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000814 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.14 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.57132 seconds (Warm-up)\n",
      "               6.48984 seconds (Sampling)\n",
      "               13.0612 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -14475.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -5952.51   5.93619e-05     0.0906687      0.5849      0.5849       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000865 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.65 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.4318 seconds (Warm-up)\n",
      "               6.30501 seconds (Sampling)\n",
      "               12.7368 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -19333.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18       -5785.3   0.000133794      0.152496           1           1       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000789 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 7.89 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.55334 seconds (Warm-up)\n",
      "               6.40548 seconds (Sampling)\n",
      "               12.9588 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -14783\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6138.93   0.000185128     0.0403923           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0.000807 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.07 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.42409 seconds (Warm-up)\n",
      "               6.95038 seconds (Sampling)\n",
      "               13.3745 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -19972.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -5834.75   0.000213542     0.0690989           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000966 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.66 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.74739 seconds (Warm-up)\n",
      "               6.63296 seconds (Sampling)\n",
      "               13.3803 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -13614.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -6030.02   0.000251146      0.136386           1           1       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.00082 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.2 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 6.22484 seconds (Warm-up)\n",
      "               6.10217 seconds (Sampling)\n",
      "               12.327 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -11954.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      16      -6102.19   0.000952494     0.0817033           1           1       19   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Doing Full MCMC for alpha=0.25\n",
      "2.47 minutes to run\n",
      "\n",
      "Gradient evaluation took 0.008349 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 83.49 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 79.7196 seconds (Warm-up)\n",
      "               67.8275 seconds (Sampling)\n",
      "               147.547 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -11916\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5585.28   8.34787e-05      0.126142       0.415           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Doing DC MCMC for alpha=0.25\n",
      "\n",
      "Gradient evaluation took 0.001127 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 11.27 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 8.00177 seconds (Warm-up)\n",
      "               6.79228 seconds (Sampling)\n",
      "               14.7941 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -12684.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5637.86    0.00107807      0.256548           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5637.86   0.000284308      0.130453           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000823 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.23 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 8.06675 seconds (Warm-up)\n",
      "               6.48331 seconds (Sampling)\n",
      "               14.5501 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -15977.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5494.47    0.00012618      0.865307      0.2399      0.2399       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5494.47   0.000152466      0.141489      0.8992      0.8992       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000796 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 7.96 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 8.05609 seconds (Warm-up)\n",
      "               6.72286 seconds (Sampling)\n",
      "               14.779 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -7751.45\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5144.18   0.000304605      0.122405           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5144.18   0.000190085     0.0804907           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0.000816 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.16 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.58274 seconds (Warm-up)\n",
      "               6.50143 seconds (Sampling)\n",
      "               14.0842 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -17862.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5601.78   0.000135224      0.238782      0.4351      0.4351       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5601.78   0.000233945     0.0726599           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000788 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 7.88 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.76092 seconds (Warm-up)\n",
      "               6.59576 seconds (Sampling)\n",
      "               14.3567 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -11760.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5654.9   0.000557617      0.186294           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -5654.9   0.000245994      0.151581           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000944 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.44 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.15532 seconds (Warm-up)\n",
      "               6.55399 seconds (Sampling)\n",
      "               13.7093 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -11460\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -5711.61   0.000189674     0.0960882           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000809 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.09 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.89779 seconds (Warm-up)\n",
      "               6.52868 seconds (Sampling)\n",
      "               14.4265 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -12775.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5292.3   0.000710466      0.454746           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -5292.3   0.000126017     0.0610234           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000825 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.25 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.9075 seconds (Warm-up)\n",
      "               6.8947 seconds (Sampling)\n",
      "               14.8022 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -21994.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5377.65    0.00035923      0.232562           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5377.65    9.9475e-05     0.0616604      0.9276      0.9276       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000856 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.56 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.47395 seconds (Warm-up)\n",
      "               6.57083 seconds (Sampling)\n",
      "               14.0448 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -14815.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -5825.28   0.000367349     0.0423772           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000959 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.59 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 7.44757 seconds (Warm-up)\n",
      "               6.52922 seconds (Sampling)\n",
      "               13.9768 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -12947.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5554.38   0.000266805      0.512514           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5554.38   0.000160478     0.0539205           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Doing Full MCMC for alpha=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0.008759 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 87.59 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "3.76 minutes to runIteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 106.572 seconds (Warm-up)\n",
      "               119.012 seconds (Sampling)\n",
      "               225.584 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -8341.82\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3880.65   0.000638794       1.07768           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -3880.64   0.000129237     0.0656694           1           1       28\n",
      "   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Doing DC MCMC for alpha=0.5\n",
      "\n",
      "Gradient evaluation took 0.000886 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.86 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 12.0794 seconds (Warm-up)\n",
      "               12.8973 seconds (Sampling)\n",
      "               24.9767 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -10781.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3888.25     0.0220238       3.31987           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      27      -3888.23   0.000195553        0.1341           1           1       30   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.001011 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 10.11 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 9.98484 seconds (Warm-up)\n",
      "               12.5379 seconds (Sampling)\n",
      "               22.5228 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -27512.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -4059.58    0.00892803       2.47794           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      26      -4059.58   5.22306e-05     0.0885052      0.2213      0.7991       32   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000849 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.49 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 10.6347 seconds (Warm-up)\n",
      "               9.55775 seconds (Sampling)\n",
      "               20.1924 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -8373.98\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -3779.9     0.0327576       14.1359           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      28      -3779.82    0.00012219     0.0510222           1           1       32   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000801 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.01 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 9.55424 seconds (Warm-up)\n",
      "               8.38509 seconds (Sampling)\n",
      "               17.9393 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -8430.48\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3864.68   0.000732371       1.10962      0.2187           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -3864.68    0.00139177     0.0821717           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000828 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.28 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 10.1692 seconds (Warm-up)\n",
      "               11.2803 seconds (Sampling)\n",
      "               21.4494 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -16557.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3745.97   0.000355668      0.518926           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -3745.97   0.000516495      0.095386           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000954 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.54 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 9.94495 seconds (Warm-up)\n",
      "               8.9161 seconds (Sampling)\n",
      "               18.8611 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -6937.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -4168.31   0.000824791       1.94409      0.3675      0.3675       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -4168.31   0.000192908     0.0798712           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0.000908 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 9.08 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 10.8808 seconds (Warm-up)\n",
      "               12.7748 seconds (Sampling)\n",
      "               23.6556 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -13386.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3783.56    0.00642454       5.58438           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      27      -3783.43   0.000186742      0.124169           1           1       33   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000787 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 7.87 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 10.0288 seconds (Warm-up)\n",
      "               8.7341 seconds (Sampling)\n",
      "               18.7629 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -9128.99\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3840.12     0.0041608       2.18139           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      26      -3840.11   0.000130678     0.0992967      0.7917      0.7917       30   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000838 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.38 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 9.80355 seconds (Warm-up)\n",
      "               11.5348 seconds (Sampling)\n",
      "               21.3384 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -49872.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3606.01    0.00896864       2.24118           1           1       26   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      26      -3606.01   0.000491836     0.0822965           1           1       33   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Gradient evaluation took 0.000814 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 8.14 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 12.4111 seconds (Warm-up)\n",
      "               12.3697 seconds (Sampling)\n",
      "               24.7807 seconds (Total)\n",
      "\n",
      "Initial log joint probability = -17313\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -3702.77    0.00752792       2.08117           1           1       25   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      26      -3702.77   5.08121e-05     0.0778915      0.4742      0.4742       33   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "# do all the MCMCs\n",
    "n_iter = 1000\n",
    "n_chains = 1\n",
    "for alph_entry in alph_entries:\n",
    "    full_mcmc(alph_entry, n_iter)\n",
    "    dc_mcmc(alph_entry, n_iter, m=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a119eac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
